summary(mtcars_reg)
conf95_lower <- 37.2851+(-5.3445-(1.96*.5591))
conf95_lower
-5.3445-(1.96*.5591)
conf95_lower <- 37.2851+(-5.3445*mean(mtcars$wt))
conf95_lower
mean(mtcars$wt)
37.2851+(-(1.96*.5591+5.3445)*mean(mtcars$wt))
predict(mtcars_reg, interval="confidence")
predict(mtcars_reg, data = mean(mtcars$wt) interval="confidence")
predict(mtcars_reg, data = mean(mtcars$wt), interval="confidence")
str(mtcars)
mtcars_reg <- lm(mpg~wt, data = mtcars)
summary(mtcars_reg)
confint(mtcars_reg, 'wt', level=0.95)
confint(mtcars_reg, mean(mtcars$wt), level=0.95)
confint(mtcars_reg, mtcars$wt, level=0.95)
mean(mtcars$wt)
confint(mtcars_reg, 'wt', level=0.95)
2000*-5.3445
sum(c(-4.5432, -2.3647, -0.1252,  1.4096,  6.8727))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
str(AlzheimerDisease)
AD_df <- data(AlzheimerDisease)
str(AD_df)
AD_df <- AlzheimerDisease
data(AlzheimerDisease)
AlzheimerDisease
?AppliedPredictiveModeling
AppliedPredictiveModeling
AppliedPredictiveModeling
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
str(adData)
str(training)
str(testing)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
str(training)
str(testing)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(training)
install.packages("Hmisc")
library(Hmisc)
hist(mixtures$SuperPlasticizer)
str(mixtures)
hist(mixtures$Superplasticizer)
summary(mixtures)
hist(log(mixtures$Superplasticizer))
log(0)
hist(sqroot(mixtures$Superplasticizer))
hist(sqrt(mixtures$Superplasticizer))
plot(mixtures$CompressiveStrength, nrow(mixtures))
plot(1:nrow(mixtures), mixtures$CompressiveStrength)
plot(1:nrow(mixtures), mixtures$CompressiveStrength, col = as.factor(FlyAsh))
plot(1:nrow(mixtures), mixtures$CompressiveStrength, col = as.factor(mixtures$FlyAsh))
plot(1:nrow(mixtures), mixtures$CompressiveStrength, col = as.factor(mixtures$Age))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?cut2
library(caret)
library(Hmisc)
?cut2
library(ggplot2)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(mixtures)
cutCement <- cut2(training$Cement, g = 3)
cutCement <- cut2(training$Cement, g = 4)
cutFlyAsh <- cut2(training$FlyAsh, g = 4)
cutAge <- cut2(training$Age, g = 4)
qplot(training$CompressiveStrength, training$FlyAsh, colour = training$Age)
qplot(training$CompressiveStrength, training$Age, colour = training$FlyAsh)
qplot(training$CompressiveStrength, 1:nrow(training), colour = training$FlyAsh)
qplot(training$CompressiveStrength, 1:nrow(training), colour = training$Age)
qplot(training$CompressiveStrength, 1:nrow(training), colour = training$FlyAsh)
library(knit)
library(knitr)
new_mean <- 3
new_var <- .6
old_mean <- 5
old_var <- .68
sp <- (9)*+(9)(.68)^2
total_df <- 18
standard error <- sqrt(((.6)^2)/9)+((.68)^2)/9))
num <- (.6^2/10 + .68^2/10)^2
den <- .6^4/10^2/9 + .68^4/10^2/9
mydf <- num/den
conf95 <- new_mean-old_mean+c(-1,1)*qt(.975,mydf)*sqrt(num)
conf95
se <- sqrt(new_var*new_var/10+old_var*old_var/10)
se
new_mean <- 3
old_mean <- 5
conf95 <- new_mean-old_mean+c(-1,1)*qt(.975,mydf)*se
conf95
n <- 10000; means <- cumsum(rnorm(n)) / (1  : n)
plot(1 : n, means, type = "l", lwd = 2,
frame = FALSE, ylab = "cumulative means", xlab = "sample size")
abline(h = 0)
?rexp
rexp(40,.2)
rexp(1000,.2)
mean(rexp(1000,.2))
mean(rexp(10000,.2))
mean(rexp(10000,1/.2))
1/.2
rexp(40,1/.2)
mean(rexp(40,1/.2))
mean(rexp(50,1/.2))
mean(rexp(60,1/.2))
mean(rexp(70,1/.2))
mean(rexp(80,1/.2))
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
par(mfrow = c(2, 3))
for (n in c(1, 10, 20)){
temp <- matrix(sample(0 : 1, n * 10000, replace = TRUE, prob = c(.9, .1)), ncol = n)
temp <- apply(temp, 1, mean)
temp <- (temp - .1) / sqrt(.1 * .9 / n)
dty <- density(temp)
plot(dty$x, dty$y, xlab = "", ylab = "density", type = "n", xlim = c(-3, 3), ylim = c(0, .5))
title(paste("sample mean of", n, "obs"))
lines(seq(-3, 3, length = 100), dnorm(seq(-3, 3, length = 100)), col = grey(.8), lwd = 3)
lines(dty$x, dty$y, lwd = 2)
}
for (n in c(1, 10, 20)){
temp <- matrix(sample(0 : 1, n * 10000, replace = TRUE), ncol = n)
temp <- apply(temp, 1, mean)
temp <- (temp - .5) * 2 * sqrt(n)
dty <- density(temp)
plot(dty$x, dty$y, xlab = "", ylab = "density", type = "n", xlim = c(-3, 3), ylim = c(0, .5))
title(paste("sample mean of", n, "obs"))
lines(seq(-3, 3, length = 100), dnorm(seq(-3, 3, length = 100)), col = grey(.8), lwd = 3)
lines(dty$x, dty$y, lwd = 2)
lamdba <- 0.2
n <- 40
hist(runif(rexp(n, 1/lambda)))
lamdba <- 0.2
n <- 40
hist(runif(rexp(n, 1/lambda)))
lambda <- 0.2
n <- 40
hist(runif(rexp(n, 1/lambda)))
par(mfrow = c(1, 1))
lambda <- 0.2
n <- 40
hist(runif(rexp(n, 1/lambda)))
# run a hisotgram of a sample of this type of dustribution
hist(runif(rexp(n, 1/lambda)))
theo_mean <- 1/lambda
?sample
mns = (sample(x = mean(rexp(n, 1/lambda)), size = 1000))
mns = (sample(x = mean(rexp(n, 1/lambda)), size = 1000, replace = TRUE))
mns
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(n, 1/lambda)))
mean(mns)
hist(mns)
theo_mean
hist(runif(rexp(n, lambda)))
mns = NULL
# loop 1000 times to get 1000 simulations
for (i in 1 : 1000) mns = c(mns, mean(rexp(n, lambda)))
theo_mean
mean(mns)
sample_mean1000 <- mean(mns)
set.seed(1000)
an exponential
# distribution
lambda <- 0.2
# setting n = 40 as set by the spec
n <- 40
# run a hisotgram of a sample of this type of dustribution
hist(runif(rexp(n, lambda)))
# set theoretical mean for comparison
theo_mean <- 1/lambda
# mean samples variable
mns = NULL
# loop 1000 times to get 1000 simulations
for (i in 1 : 1000) mns = c(mns, mean(rexp(n, lambda)))
hist(mns)
# 1 Show the sample mean and compare it to the theoretical mean of the distribution.
theo_mean
# theoretical mean = 1/lambda = 1/.2 = 5
# mean of sample means after running 1000 simulations of the exponential rexp(40, .2)
sample_mean1000 <- mean(mns)
sample_mean1000
# 5.008442
hist(rexp(n, lambda)))
hist(rexp(n, lambda))
theo_sample_diff <- sample_mean1000-theo_mean
theo_sample_diff
library(MASS)
?shuttle
logistic_auto <- glm(data = shuttle, formular = auto~wind, family = "binomial")
logistic_auto <- glm(data = shuttle, formula = auto~wind, family = "binomial")
str(shuttle)
logistic_auto <- glm(data = shuttle, formula = use~wind, family = "binomial")
logistic_auto
summary(logistic_auto)
exp(coefficients(logistic_auto))
logistic_auto2 <- glm(data = shuttle, formula = use~wind+magn, family = "binomial")
exp(coefficients(logistic_auto2))
logistic_auto2
summary(logistic_auto2)
logistic_auto3_1 <- glm(data = shuttle, formula = use~wind, family = "binomial")
coefficients(logistic_auto3_1)
logistic_auto3_2 <- glm(data = shuttle, formula = (1-use)~wind, family = "binomial")
coefficients(logistic_auto3_2)
logistic_auto3_2 <- glm(data = shuttle, formula = (!use)~wind, family = "binomial")
coefficients(logistic_auto3_2)
logistic_auto3_2 <- glm(data = shuttle, formula = (as.factor(abs(1-as.numeric(use))))~wind, family = "binomial")
coefficients(logistic_auto3_1)
coefficients(logistic_auto3_2)
logistic_auto3_2 <- glm(data = shuttle, formula = !use~wind, family = "binomial")
str(shuttle$use)
summary(shuttle$use)
shuttle$use
factor(shuttle$use)
ifelse
?ifelse
shuttle$dummy <- ifelse(shuttle$use == "auto", 0, 1)
shuttle$dummt
shuttle$dummy
shuttle$dummy <- ifelse(shuttle$use == "auto", 0, 1)
logistic_auto3_1 <- glm(data = shuttle, formula = dummy~wind, family = "binomial")
coefficients(logistic_auto3_1)
shuttle$dummy <- ifelse(shuttle$use == "auto", 1, 0)
logistic_auto3_2 <- glm(data = shuttle, formula = dummy~wind, family = "binomial")
coefficients(logistic_auto3_2)
?InsectSprays
str(InsectSprays)
poisson_glm_insect <- glm(data = InsectSprays, formula = spray ~ count, family = "Poisson")
?glm
poisson_glm_insect <- glm(data = InsectSprays, formula = spray ~ count, family = "poisson")
poisson_glm_insect <- glm(data = InsectSprays, formula = spray, family = "poisson")
poisson_glm_insect <- glm(data = InsectSprays, formula = spray ~ count, family = "poisson", na.rm = TRUE)
poisson_glm_insect <- glm(formula = count ~ spray, family = "poisson", data = InsectSprays)
summary(poisson_glm_insect)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
x
poisson_glm_insect <- glm(formula = count ~ spray, family = "poisson", data = InsectSprays)
summary(poisson_glm_insect)
2.67415/(2.67415+.05588)
1/11.05588
1/1.05588
poisson_glm_insect
poisson_glm_insect <- glm(formula = count ~ spray, family = "poisson",
data = InsectSprays[InsectSprays$spay == "A" |InsectSprays$spay == "B"])
summary(poisson_glm_insect)
poisson_glm_insect <- glm(formula = count ~ spray, family = "poisson",
data = InsectSprays[InsectSprays$spay == "A" |InsectSprays$spay == "B",])
poisson_glm_insect <- glm(formula = count ~ spray, family = "poisson",
data = InsectSprays[InsectSprays$spray == "A" | InsectSprays$spray == "B",])
summary(poisson_glm_insect)
```
2.67415/(2.67415+.05588)
1/(1.05588)
library(swirl)
swirl()
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
?gbm
str(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
str(vowel.train)
set.seed(33833)
library(caret)
vowel_rf = train(y~., data = vowel.train, method = "rf", metric = "Accuracy")
# error rate
vowel_rf = train(y~., data = vowel.train, method = "rf", metric = "Accuracy")
predictTest <- predict(vowel_rf), type = "raw", newdata = vowel.test)
confusionMatrix(vowel.test$y, predictTest)
predictTest <- predict(vowel_rf, type = "raw", newdata = vowel.test)
confusionMatrix(vowel.test$y, predictTest)
vowel_gbm = train(y~., data = vowel.train, method = "gbm", metric = "Accuracy")
?gbm
predictTest2 <- predict(vowel_gbm, type = "class", newdata = vowel.test)
summary(confusionMatrix(vowel.test$y, predictTest2))
predictTest2 <- predict(vowel_gbm, type = "raw", newdata = vowel.test)
summary(confusionMatrix(vowel.test$y, predictTest2))
confusionMatrix(vowel.test$y, predictTest2)$table
?accuracy
?trace
?tr
install.packages("psych")
library(psych)
?tr
nrow(vowel.test)
tr(confusionMatrix(vowel.test$y, predictTest2)$table)
predictTest2_accuracy <- tr(confusionMatrix(vowel.test$y, predictTest2)$table)/nrow(vowel.test)
predictTest2_accuracy
predictTest2 <- predict(vowel_gbm, type = "raw", newdata = vowel.test)
confusionMatrix(vowel.test$y, predictTest)
predictTest_accuracy <- tr(confusionMatrix(vowel.test$y, predictTest)$table)/nrow(vowel.test)
predictTest_accuracy
install.packages("Agreement")
?Agreement
library(Agreement)
?Agreement
summary(predictTest)
summary(predictTest2)
combined_predictions <- predictTest[predictTest == predictTest2]
summary(combined_predictions)
sum(combined_predictions)
tr(combined_predictions)
combined_predictions
predictTestC_accuracy <- tr(confusionMatrix(vowel.test$y, predictTestC)$table)/nrow(vowel.test)
predictTestC_accuracy
predictTestC_accuracy <- tr(confusionMatrix(vowel.test$y, combined_predictions)$table)/nrow(vowel.test)
predictTestC_accuracy
combined_predictions
combined_predictions <- predictTest[predictTest == predictTest2]
summary(combined_predictions)
predictTestC <- predict(combined_predictions, type = "raw", newdata = vowel.test)
predictTestC_accuracy <- tr(confusionMatrix(vowel.test$y, predictTestC)$table)/nrow(vowel.test)
predictTestC_accuracy
table(combined_predictions, vowel.test$y)
table(combined_predictions, summary(vowel.test$y)
)
# q2 - Load the Alzheimer's data using the following commands
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?gam
library(ISLR); data(Wage); library(ggplot2); library(caret);
predDF <- data.frame(predictTest,predictTest2,y=vowel.train$y)
predictTest_accuracy <- tr(confusionMatrix(vowel.test$y, predictTest)$table)/nrow(vowel.test)
predictTest_accuracy
# gradient boosted regression
vowel_gbm = train(y~., data = vowel.train, method = "gbm", metric = "Accuracy")
confusionMatrix(vowel.test$y, predictTest2)$table
predictTest2_accuracy <- tr(confusionMatrix(vowel.test$y, predictTest2)$table)/nrow(vowel.test)
predictTest2_accuracy
str(training)
Alz_rf = train(diagnosis~., data = training, method = "rf")
predictTest <- predict(Alz_rf, type = "raw", newdata = testing)
confusionMatrix(testing$diagnosis, predictTest)
predictTest_accuracy <- tr(confusionMatrix(testing$diagnosis, predictTest)$table)/nrow(testing)
predictTest_accuracy
Alz_gbm = train(diagnosis~., data = training, method = "gbm")
predictTest2 <- predict(Alz_gbm, type = "raw", newdata = testing)
# confusionMatrix(vowel.test$y, predictTest2)
confusionMatrix(vowel.test$y, predictTest2)$table
predictTest2_accuracy <- tr(confusionMatrix(testing$diagnosis, predictTest2)$table)/nrow(testing)
predictTest2_accuracy
predictTest_accuracy
combModFit <- train(y~.,method="gam",data=predDF, metric = "Accuracy")
combPred <- predict(combModFit,predDF)
summary(predictTest2)
predDF <- data.frame(predictTest,predictTest2,y=vowel.train$y)
combModFit <- train(y~.,method="gam",data=predDF, metric = "Accuracy")
combPred <- predict(combModFit,predDF)
# predictTestC <- predict(combined_predi
Alz_lda = train(diagnosis~., data = training, method = "lda")
predictTest3 <- predict(Alz_lda, type = "raw", newdata = testing)
# confusionMatrix(vowel.test$y, predictTest2)
confusionMatrix(vowel.test$y, predictTest3)$table
predictTest3_accuracy <- tr(confusionMatrix(testing$diagnosis, predictTest3)$table)/nrow(testing)
predictTest3_accuracy
predDF <- data.frame(predictTest,predictTest2,diagnosis = testing$diagnosis)
combModFit <- train(diagnosis~.,method="rf",data=predDF)
combPred <- predict(combModFit,predDF)
predictTestC_accuracy <- tr(confusionMatrix(testing$diagnosis, combPred)$table)/nrow(testing)
predictTestC_accuracy
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Set the seed to 233 and fit a lasso model to predict Compressive Strength. Which variable is the last coefficient to
# be set to zero as the penalty increases? (Hint: it may be useful to look up ?plot.enet).
set.seed(233)
?ela
?elm
?lasso
install.packages('enet')
str(training)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Set the seed to 233 and fit a lasso model to predict Compressive Strength. Which variable is the last coefficient to
# be set to zero as the penalty increases? (Hint: it may be useful to look up ?plot.enet).
set.seed(233)
concrete_enet = train(CompressiveStrength~., data = training, method = "enet")
predictTest <- predict(concrete_enet, newdata = testing)
predictTest_error <- sqrt(sum((predictTest-testing$CompressiveStrength)^2))
predictTest_error
?plot.enet
library(plot.enet)
plot(plot(concrete_enet, xvar = "penalty")
)
?plot.enet
plot(concrete_enet, xvar = "penalty")
plot(concrete_enet)
plot(concrete_enet, xvar = "step")
plot(concrete_enet)concrete_enet = train(CompressiveStrength~., data = training, method = "lasso")
concrete_enet = train(CompressiveStrength~., data = training, method = "lasso")
plot(concrete_enet, xvar = "penalty")
plot(concrete_enet, xvar = "penalty", use.color = TRUE)
predictTest_error <- sqrt(sum((predictTest-testing$CompressiveStrength)^2))
predictTest_error
summary(concrete_enet)
summary(concrete_enet$penalty)
sconcrete_enet$penalty
concrete_enet$penalty
concrete_enet
?lasso
setwd("~/datasciencecoursera/Practical Machine Learning")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages(forecast)
install.packages("forecast")
library(forecast)
?bats
?accuracy
?forecast
visitors.fit <- bats(training)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
visitors.fit <- bats(tstrain)
plot(forecast(tstrain))
lines(testing,col="red")
summary(visitors.fit)
visitors.fit
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
libary(e1071)
library(e1071)
concrete_svm = train(CompressiveStrength~., data = training, method = "svm")
predictTest <- predict(concrete_svm, newdata = testing)
# confusionMatrix(vowel.test$y, predictTest2)
predictTest_error <- sqrt(sum((predictTest-testing$CompressiveStrength)^2))
predictTest_error
?svm
concrete_svm = svm(CompressiveStrength~., data = training)
predictTest <- predict(concrete_svm, newdata = testing)
# confusionMatrix(vowel.test$y, predictTest2)
predictTest_error <- sqrt(sum((predictTest-testing$CompressiveStrength)^2))
predictTest_error
print(predictTest)
print(concrete_svm)
?predict
